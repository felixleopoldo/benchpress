import json
import jsonschema
from jsonschema import validate
import snakemake.utils
import sys, getopt
import shutil
import filecmp
from pathlib import Path
import os

include: "rules/helper_functions.py"

check_system_requirements()

# This is a workaround. Needed a variable for the configfilename
# and this seemed to be the only way. But there are probably better ways.
args = sys.argv
configfilename = "config/config.json"
i = 0
for arg in args:
    if arg == "--configfile" or arg == "--configfiles":  # This is strange
        configfilename = args[i + 1]
        break
    i += 1


configfile: configfilename

with open("workflow/schemas/config.schema.json") as json_file:
    schema = json.load(json_file)

for p in Path("workflow/rules/structure_learning_algorithms/").iterdir():
    item = schema["properties"]["resources"]["properties"][
        "structure_learning_algorithms"
    ]["properties"]

    item[p.name] = {
        "$ref": "../rules/structure_learning_algorithms/{}/schema.json".format(p.name)
    }

for p in Path("workflow/rules/graph/").iterdir():
    item = schema["properties"]["resources"]["properties"][
        "graph"
    ]["properties"]

    item[p.name] = {
        "$ref": "../rules/graph/{}/schema.json".format(p.name)
    }

for p in Path("workflow/rules/parameters/").iterdir():
    item = schema["properties"]["resources"]["properties"][
        "parameters"
    ]["properties"]

    item[p.name] = {
        "$ref": "../rules/parameters/{}/schema.json".format(p.name)
    }

for p in Path("workflow/rules/data/").iterdir():
    item = schema["properties"]["resources"]["properties"][
        "data"
    ]["properties"]

    item[p.name] = {
        "$ref": "../rules/data/{}/schema.json".format(p.name)
    }

# Write the definitions
# Generate the evaluation schemas
for p in Path("workflow/rules/evaluation/").iterdir():
    item = schema["definitions"]["benchmark_setup"]["properties"]["evaluation"]["properties"]
    item[p.name] = {
        "$ref": "../rules/evaluation/{}/schema.json".format(p.name)
    }

# Yes this is a hack to use snakemakes built in validator.
with open("workflow/schemas/tmp.config.schema.json", "w") as outfile:
    outfile.write(json.dumps(schema, indent=4))

snakemake.utils.validate(config, "schemas/tmp.config.schema.json")

include: "rules/docker_images.smk"

container: docker_image("benchmark")

rule all:
    input:
        get_active_rules,

rule copy_configs:
    input: 
        "config/"
    output:
        directory("config/copies")
    shell:
        "cp -r {input} {output}"

# Read which modules are MCMC module (have graphtraj output).
mcmc_modules = []
for p in Path("workflow/rules/structure_learning_algorithms/").iterdir():
    if p.name.startswith("."): # Skip hidden files
        continue
    with open(p/"info.json") as json_file:
        info = json.load(json_file)
        if "graphtraj" in info["outputs"]:
            mcmc_modules.append(p.name)

# Validate JSON file based on its values.
include: "rules/validate.py"
include: "rules/module_patterns.py"
include: "rules/module_strings.py"
include: "rules/filename_patterns.py"

# Include the graph modules
for p in Path("workflow/rules/graph/").glob("[!.]*"):
    module_name = p.name  # This is used inside the module to get their names
    if (p / "rule.smk").is_file():
        if p.name in pattern_strings or (p.name == "fixed_graph"):

            include: Path("rules/graph/", p.name, "rule.smk")


# Include the parameters modules
for p in Path("workflow/rules/parameters/").glob("[!.]*"):
    module_name = p.name  # This is used inside the module to get their names
    if (p / "rule.smk").is_file():
        if (p.name in pattern_strings) or (p.name == "fixed_params"):

            include: Path("rules/parameters/", p.name, "rule.smk")


# Include the data modules
for p in Path("workflow/rules/data/").glob("[!.]*"):
    module_name = p.name  # This is used inside the module to get their names
    if (p / "rules.smk").is_file():
        if (p.name in pattern_strings) or (p.name == "fixed_data"):
            include: Path("rules/data/", p.name, "rules.smk")
    if (p / "rule.smk").is_file():
        if (p.name in pattern_strings):
            include: Path("rules/data/", p.name, "rule.smk")


# Include the structure_learning_algorithms modules
for p in Path("workflow/rules/structure_learning_algorithms/").glob("[!.]*"):
    module_name = p.name  # This is used inside the module to get their names
    if (p / "rule.smk").is_file():
        if p.name in pattern_strings:
            # set the module name here
            include: Path("rules/structure_learning_algorithms/", p.name, "rule.smk")
            if p.name in mcmc_modules:
                rule:
                    name:
                        p.name + "_estimation"
                    input:
                        traj=alg_output_seqgraph_path_fine_match(p.name),
                    output:
                        adjmat=adjmat_estimate_path_mcmc(p.name)
                    params:
                        graph_type="chordal", # not used
                        estimator="{mcmc_estimator}",
                        threshold="{threshold}",
                        burnin_frac="{burnin_frac}",
                    container:
                        docker_image("pydatascience")
                    script:
                        "scripts/evaluation/graphtraj_est.py"
# Include the evaluation modules

for p in Path("workflow/rules/evaluation/").glob("[!.]*"):
    for bmark_setup in config["benchmark_setup"]: # Maybe includes same module multiple times
        if p.name not in bmark_setup["evaluation"]:
            continue
        if (p / "rules.smk").is_file():
            include: Path("rules/evaluation/", p.name, "rules.smk")
        elif (p / "rule.smk").is_file():
            include: Path("rules/evaluation/", p.name, "rule.smk")

rule convert_edge_constraints:
    input:
        edgeConstraints="resources/extra_args/{edgeConstraints}"
    output:
        edgeConstraints_in_format="resources/constraints/{edgeConstraints}-{package}"
    wildcard_constraints:
        edgeConstraints=r".*\.json"
    params:
        package = "{package}"
    script:
        "scripts/utils/convert_edge_constraints_all.R"
